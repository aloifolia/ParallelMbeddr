\chapter{Conclusion}
\label{summary}

This thesis showed an approach to leverageing mbeddr's language extensibility support for providing advanced support for parallel programming in the embedded domain with C. By developing the new language abstraction ParallelMbeddr on top of mbeddr, the work provided an explicit parallelization approach for task based parallelism. For this purpose the concepts `task' and `future' were developed. It was found that these concepts enable a convenient approach to parallel execution of code: The definition of code that shall be executed in parallel is significantly facilitated when compared to working with low level libraries like POSIX threads (as can be seen at the generated code which makes use of pthreads). The thread-safe communication between tasks was realized by shared resources which wrap data to be shared between tasks. The communication via shared resources was restricted to explicit synchronization contexts that the user had to define by making use of the synchronization statement concept.
By enhancing the type system with a shared data type for shared resources and restricting the ways shared resources may be used, ParallelMbeddr thus simplifies reasoning of side-effects of communication between tasks. Thus, the creation of thread-safe code should be facilitated. By applying explicit synchronization, the system forces the programmer to think about the right scoping of synchronization contexts. The guaranteed thread-safety, however, is currently limited to low-level data-dependencies. Languages like \AE minium show how to approach this problem and should be used as paragons for future extensions of ParallelMbeddr: Dependencies between data should be expressed at the definition of the data, not only when it is used. Otherwise, the language suffers from the danger of data-races resulting from higher-level data-dependencies just as Java does with low-level data-dependencies, if methods or statement blocks are not properly synchronized.

As in mbeddr the safety checks happen in the background in real-time, the user directly receives feedback concerning safety issue of the written code. However, this approach demands the checks to be not too complex computational-wise. Hence, the code currently burdens the user with lexical scopes of synchronization statements. One approach to mitigate this problem in the future is the introduction of further data types or type annotations (for instance \CODE{synced<t>}) by the user, which diminish the use of synchronization -- hence, locks in the generated code -- in the first place. Another type-based approach would be the introduction of owned pointers and borrowed pointers, as they are implemented in Rust, which eliminate the necessity for synchronization altogether. Such type advances could both make the code more explicit (and certainly more complicated) and accelerate the generated code. While these approaches cede the reduction of locks to the user, inspired by research on Java, this work showed how to perform performance optimizations in the compilation process. It presented algorithms for the reduction of single-task and read-only locks, which share the property of removing locks for whole shared resources, whenever this is possible. Approaches for the removal of recursive locks were given next. The test results in the evaluation showed evidence, that specifically for the current lexical scopes of synchronizations (and the necessarily resulting recursively locks), such optimization should certainly be applied, in order to mitigate the resulting synchronization management overhead. On the other hand, single-task locks seem to be either a code smell for an unnecessary utilization of shared data by the user. Or they result from re-use of library code. The programming and re-use of library code which makes use of ParallelMbeddr's concepts is currently not supported and should be a concern of future research. As the optimization algorithms generally benefit from an inter-procedural alias-analysis, which can not be performed when libraries are written, optimizations of such code, too, is left to future research. While for these reasons and the similarity to read-only locks, single-tasks where not evaluated (although extensively tested), the removal of read-only locks was. It was shown that the optimization of shared containers of shared data can in some cases improve the performance of the generated code. The last optimization, the data-dependence safe narrowing of synchronization statements can also improve the performance of the executed code significantly. The presented optimizations should, however, be seen as prototypes, since in the implementation they support only simple data structures. Additionally, the lack of a precise alias analysis in mbeddr limits the scope of optimizations that can safely be executed with the prototypical analysis that was implemented as a surrogate. For the evaluation, the recursive-lock reduction therefore was configured to perform optimizations which were safe for the considered scenarios, but can be dangerous -- in terms of thread-safety -- for others. Two important fields of future research should therefore be the extension of mbeddr with a precise alias-analysis and general optimization support for more complex data structures. The presented algorithms should greatly profit from this.

Another task for the future is the development of algorithms which do not, unlike the presented ones, assume a simultaneous execution of threads but, instead, take the succeeding and interleaved execution of tasks into account. This way, those locks could for instance be removed which synchronize data that up until a certain point are only used by a single task. Additonally, apart from static analysis for the detection of shared data of interleaved tasks which are guaranteed to be used by only one task at a time, model checkers like CBMC could be employed for the same purpose. CBMC can be used to perform test-runs of code which makes use of assertions. Additionally, for programs that are simple enough, CBMC can verify the absence of false assertions by unwinding all possible paths through the program \cite{CBMCTutorial}.\footnote{For instance, if loops and recursive functions need to be evaluated more often than the user allows, they will limit the assertions that CBMC can verify.} An optimization analysis could exploit this feature by assigning access counters to shared resources, removing synchronization statements and asserting that despite this removal, in every possible run of the program, a certain shared resource is always executed by at most one task at a time. For such resources the according locks could be removed. At the time this thesis was written, however, CBMC was not ready to be used yet for multi-threading. In this regard the applicability of CBMC for optimizations has to be left to future research.

Apart from optimization concerns, the scenarios presented in this work showed that for instance the implementation of shared resources as C structures may entail the generation of many according declarations. Without concrete scenarios from the industry it remains uncertain whether the amount of generated code has a negative impact on the applicability of ParallelMbeddr. Nevertheless, future research should investigate the impact of padding that may be inserted into the generated structs and whether according optimization should be pursued. The scenarios further showed that general parallelization problems, like the dining philosophers problem and map-reduce via communication queues, can be implemented with ParallelMbeddr. The performance and scalability of the resulting code does not only depend on the quality of performed optimizations, but also on the general utilization of synchronization. For instance, the pi-example of section (TODO) showed that the implementation of a queue and communication via the queue require a busy-wait approach on the application level. Although concepts like message passing can therefore in a sense also be implemented by the user, it is questionable if the performance and usability of such an implementation have already reached their limits. Therefore, native support for concepts like message-passing or condition variables could both improve the usability and may, in certain cases, enhance the performance of the written code.

Overall, the thesis showed, how first-class language support on top an existing language can both ease the writing of parallel data-race free code and use the compiler for optimizing the resulting code in terms of synchronization overhead. To the knowledge of the writer, it also gave the first implementation of such an approach for C in a real-world setting, the development environment mbeddr. While this work laid the foundation for parallelization support for mbeddr, it showed how much potential reside in the chosen approach and how further enhancements can raise the accomplishments. From an industrial point of view, one main task for the future will be the complete integration of ParallelMbeddr with all of mbeddr's various language concepts and the stabilization for real-world applications.
