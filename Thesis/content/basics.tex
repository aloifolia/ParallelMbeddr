\chapter{Background}

\section{Processes and Threads}
Every program in execution which may be delayed or interrupted is represented by a process. A process typically has its own protected data (via virtual memory) and execution state and consists of one or more threads. A thread, also known as lightweight process, shares some of the memory with its process but has its own execution state and thread-local storage as needed\cite[p.~20]{PrinciplesOfModernOSs}. In the course of programming language and operating system development several variants of threads have been devised, among others green threads, fibers and coroutines which mainly differ in how they are managed.

\section{Parallelism and concurrency}
If multiple threads are ``in the middle of executing code at the same time''\cite[p.~124(?)]{MultiProgWithJavaTech} they are processed concurrently. They can be executed at the same time on different processors or interleaved on a single processor which means that they are executed in an alternating way. The former is also called parallelism. Parallelism generalized to ``the quality of occuring at the same time''\cite[p.~91]{OSs_AConceptBasedApproach} can manifest in different ways %\footnote{Although many of the characteristics of parallelism are also present for interleaved concurrency in order to have a clear distinction between the terms the latter will be used to emphasize .}.

\section{Types of parallelism}
At least four different kinds of parallelism have been conceived. From an application programmer's view seen at a very low level exist bit-level parallelism and instruction-level parallelism. Bit-level parallelism is concerned with increasing the word size of processors in order to reduce the amount of cycles that are needed to perform an instruction\cite[p.~15]{ParCompArchitecture_HW/SW_Approach}. Instruction-level parallelism, also called pipelining, is the simultaneous utilization of multiple stages of the execution pipeline of the processor. Both bit-level parallelism and instruction-level parallelism primarily reside on the hardware level and the operating system level and are, thus, no subject of this work. Data parallelism is present if the same calculation is performed on multiple sets of data and can be regarded as a specialization of task parallelism which denotes the simultaneous execution of different calculations ``on either the same or different data''\cite[p.~125]{ParCompArchitecture_HW/SW_Approach}. The latter being the more general approach to software-level parallelism is the subject of this work.

\section{Data races}
When a process consists of multiple concurrently running threads which have access to the shared data of their process a second class of errors that is unique to parallel (and distributed) programming arises. These so-called synchronisation errors occur due to data races and are a result of the general non-atomicity of computations and memory references. Data races--- also known as race conditions--- are defined as at least ``two unsynchronised memory references by two processes on one memory location, of which at least one reference is a write access''\cite[p.~327]{ParallelComputing}\footnote{As the definition implies data races are not limited to threads and the shared process data. E.g. file-based race conditions can even occur between two different processes\cite{OfficialISC2Guide}. Since this work is about parallelization of single processes other kinds of race conditions are not further considered.}. Such data races can result in inconsistent program states and non-deterministic program behavior since the order in which the concerned memory is accessed might change. In order to deal with this issue three main paradigms have been conceived in parallel programming.

\section{Communication model: shared memory}
The memory model that implicitly underlied the former treatment of processes which share some data with their threads is formally known as \textit{shared memory} . In this model communication between entities is realized by shared-memory regions which are written to and read from\cite[p.~138]{OperatingSystems_by_Haldar}\footnote{As for race conditions the model is not limited to intra-process communication via threads or similar approaches to parallelization. Communication between two processes can also be realized via shared memory but is not in the scope of this work.}. Data races can be avoided with the help of the low-level synchronization primitive \textit{mutex}\footnote{Semaphores as a second synchronization primitive are closely related to mutexes. Since they do not provide further insights for the discussion they are not further investigated in this work.}. A mutex can be locked by exactly one thread. Any other thread that tries to lock the same mutex is blocked until the locking thread releases the mutex\cite{AdvancedLinuxProgramming}. Thus, code regions can be protected by having threads synchronize over mutexes that protect these regions. One of the disadvantages of mutexes is that they are not tightly coupled to the data or computation that they protect. It is the programmer's duty to take care of the sane utilization of a certain mutex. Therefore various higher-level synchronization measures like monitors in Java(TODO:  reference) and synchronized classes in D(TODO: forward reference) were developed. These measures are usually built on top of mutexes\cite[p.~25]{TamingJavaThreads}. Another disadvantage of mutexes is their vulnerability for deadlocks which means that multiple processes are in a state where ``each is waiting for release of a resource which is currently held by some other process''\cite[p.~119]{IntroductionToOperatingSystems} such that no progress will ever finish executing\cite[p.~2-3]{OperatingSystems_by_Dhotre}.

\section{Communication model: message passing}
Whereas communication in the shared memory paradigm happens rather implicitly it is done explicitly in the \textit{message passing} paradigm. Message passing originates from Hoare's paper on Communicating Sequential Processes (CSP)(TODO: reference!). In CSP messages are sent from one entity to another. ``The sender waits until the receiver has accepted the message (\textit{synchronous} message passing)''\cite[p.~138]{DistributedSharedMemory}. Message passing with asynchronous message sents were deployed by the actor model\cite{UniversalModularACTORFormalism} and pi calculus\cite{ThePolyadicPi-Calculus}. Although message passing avoids shared data and realizes communication generally via copies of data\footnote{Actually shared data is often used in implementations of message passing models in order to enhance the performance. Furthermore it exists on the language level like in terms of monitors that were developed by Hoare to reduce deadlocks in CSP. The main notion of the message passing concept nevertheless goes without shared data.} it still suffers from potential race conditions\cite{DebuggingRaceConditions}. 

\section{Communication model: transactional memory}
\textit{Transactional memory} provides a non-blocking\footnote{TODO: explain} memory model which enables communication via ``lightweight, \textit{in-memory} transactions''\cite[p.~3]{PrinciplesOfTransactionalMemory} which are code blocks that from a programmer's perspective are executed atomically. The illusion of atomicity is realized by the underlying transaction system which may execute transactions in parallel and has to take care of conflicting reads and writes in transactions\footnote{To this end the corresponding transactions may need to be reexecuted as a whole.}\cite{TransactionalMemory}. Transactional memory can either be realized in hardware or in software. While the former promises a better performance it demands specific hardware. Software transactional memory on the other hand seems to suffer from comparatively ``poor performance''\cite[p.~13]{TransactionalProgrammabilityAndPerformance}.

\section{Coarse- and fine-grained synchronization}
In order to keep structures and computations synchronized the simplest approach to avoid data races is to use the available measures like locks or transactions as broadly as possible. E.g. transactions could be widened to hold every operation a thread has to execute. As every synchronization is basically a serialization of otherwise parallel executed code such coarse-grained synchronization would eliminate the benefits of parallel execution. On the other hand fine-grained synchronization can introduce race conditions if the programmer misses some locking policy. In addition the acquisition of every lock takes time which can become an issue with increasing locking counts. Therefore a trade-off between locking-overhead and scalability problems has to be found\cite[pp.~1-2]{PrinciplesOfTransactionalMemory}.

\section{Embedded programming}
``An embedded system is a computerized system that is purpose-built for its application.''\cite[p.~1]{MakingEmbeddedSystems} Due to its narrow scope and monetary constraints induced by the application domain the hardware of such systems is often constrained to the point that it just accomplishs the job\cite{MakingEmbeddedSystems}. Thus, the memory consumption of the resulting program is one main issue to be considered in embedded programming. Additionally, for real-time systems which constitute a subclass of embedded systems not only the correctness of computations but also the consumed time determine their quality and usefulness \cite[pp.~1-2]{SoftReal-TimeSystems}. Therefore the predictability of the program's execution time becomes an issue for real-time systems\footnote{Mbeddr does not have first-class support for the quantification of related parameters like the worst-case execution time (WCET)\cite[p.~8]{SoftReal-TimeSystems}, yet. For this reason predictability is a lesser concern of this thesis and will be reflected primarily in the careful consideration of the CPU consumption and processing time of the implementation.}.

\section{MPS and mbeddr}
``JetBrains MPS\footnote{http://jetbrains.com/mps} is an open source [...] language workbench developed over the last ten years by JetBrains. ''\cite{GenericTools_SpecificLanguages} As such it provides a projectional editor which lets the user directly work on the abstract syntax tree (AST) of the program\cite{LanguageWorkbenches}. It supports the development and composition of potentially syntactically ambiguous modular language extensions in combination with the development of integrated development environments (IDEs) or extensions thereof. Mbeddr is an extension of MPS tailored for the embedded software development in C. Every program written in the mbeddr IDE is translated to C99 source code which are then further processed by the gcc tool chain\footnote{http://gcc.gnu.org/}. Every new language construct that is introduced as an extension of the existing language of mbeddr (and any existing construct) is represented by a \textit{concept}. The complete definition of a concept comprises the definition of certain \textit{language aspects}: the structure of a concept is defined in an equally named aspect which contains the abstract syntax of the concept in the abstract syntax tree (AST) of the program. The visual representation of the concept, its concrete syntax is defined in the \textit{editor aspect}. A type aspect may contain a type inference rule for a concept and further \textit{non-typesystem rules} which restrict the way a concept may be used. In a formal meta-language the latter are usually part of the inference rules but are kept seperately in MPS to diminish the complexity of inference rules and be able to extend them easily. At last the \textit{generator} ``defines the denotational semantics for the concepts in the language''\cite{GeneratorUserGuide}. Thus, the aspect describes the translation of concepts into concepts of the base language.
The implementation of C in mbeddr does not only provide extensions to the core of C but also has a few differences to the basis of the C99 standard. They will be introduced as needed.

\section{C}
\label{cBasics}
The semantics of C differ from modern object-oriented languages like Java in a variety of ways. In order to clarify some of the choices that were made for the design and implementation of ParallelMbeddr the most relevant differences shall be outlined. Like Java C leverages pass-by-value semantics for function parameters. Differently though it generally copies the referenced values into the memory that is allocated for function calls whereas Java copies the references themselves. Thus a change to a field of a struct instance that was copied in such a way does not affect the original struct instance\footnote{The only way to avoid this behaviour is to copy the memory addresses of values as pointers into functions.}. On the other hand arrays are treated like pointers which becomes evident when they are passed to functions. Hence a change of an entry of an array argument actually changes the array that is referred to by a variable on the caller site. In order to have an array be copied into a function it can be declared as a struct field which due to the copy semantics for structs ensures that like any other field of the struct instance the array's value is copied into the newly created struct instance. The copy semantics are not restricted to function arguments but also extend to function return values and variable assignments. The ``pass-by-pointer-value'' semantics for arrays implies that arrays cannot be returned from functions as is done in Java. Instead corresponding pointers are returned. This means that it is not safe to return an array, respectively a pointer thereof, from a function if the array resides on the area of the stack that was allocated for this function\footnote{Otherwise the pointed-to memory of the returned array pointer would become deallocated after the return of the called function. This again would cause the return of a dangling pointer into the receiver of the returned value, i.e. a pointer that does not point to a valid memory address.}. 
A peculiarity of C is that global variables may only be initialized with constant expressions such that it is not possible to initialize a global variable with an arbitrary function call of a proper type\cite[p.~48]{CForBASICProgrammers}.

\TODO{Add explanations for MPS aspects, type-system checking rules... as needed}

\TODO{Maybe add section for explicit vs. implicit parallel programming, look at Programming Distributed Systems by H. E. Bal, pp. 113-114}

\TODO{Implementation: coarse- vs. fine-grained synchronization, problems => implicit synchronization not exhaustive => optimization for safe lock avoidance helpful}